{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 06 17:36:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 445.87       Driver Version: 445.87       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 17%   55C    P0    66W / 260W |    825MiB / 11264MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU                  PID   Type   Process name                  GPU Memory |\n",
      "|                                                                  Usage      |\n",
      "|=============================================================================|\n",
      "|    0                 1112    C+G   D:\\WeChat\\WeChatApp.exe         N/A      |\n",
      "|    0                 1276    C+G   Insufficient Permissions        N/A      |\n",
      "|    0                 3612    C+G   ...stic_Light\\LEDKeeper2.exe    N/A      |\n",
      "|    0                 3760    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0                 4896    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0                11136    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0                12032    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0                12524    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0                12836    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0                12904    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0                13492    C+G   ...slack\\app-4.6.0\\slack.exe    N/A      |\n",
      "|    0                15220    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0                15552    C+G   D:\\WeChat\\WeChatWeb.exe         N/A      |\n",
      "|    0                17164    C+G   ...d\\app-0.0.306\\Discord.exe    N/A      |\n",
      "|    0                19324    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0                21500    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0                40492    C+G   ...ne\\bin\\webwallpaper32.exe    N/A      |\n",
      "|    0                43692    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0                49580    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0                50376    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Using GPU to train CNN\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model, Sequential, load_model, Input\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether using GPU\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images\n",
    "Train=pd.read_csv('plant-pathology-2020-fgvc7/train.csv')\n",
    "Test=pd.read_csv('plant-pathology-2020-fgvc7/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing images\n",
    "img_size=100\n",
    "Train_image=[]\n",
    "for name in Train['image_id']:\n",
    "    path='plant-pathology-2020-fgvc7/images/'+name+'.jpg'\n",
    "    img=cv2.imread(path)\n",
    "    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n",
    "    Train_image.append(image)\n",
    "\n",
    "Test_image=[]\n",
    "for name in Test['image_id']:\n",
    "    path='plant-pathology-2020-fgvc7/images/'+name+'.jpg'\n",
    "    img=cv2.imread(path)\n",
    "    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n",
    "    Test_image.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (1821, 100, 100, 3)\n",
      "Test Shape: (1821, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing the channels - image to array\n",
    "X_train = np.ndarray(shape=(len(Train_image), img_size, img_size, 3),dtype = np.float32)\n",
    "i=0\n",
    "for image in Train_image:\n",
    "    X_train[i]=img_to_array(image)\n",
    "    X_train[i]=Train_image[i]\n",
    "    i=i+1\n",
    "X_train=X_train/255\n",
    "print('Train Shape: {}'.format(X_train.shape))\n",
    "\n",
    "X_test = np.ndarray(shape=(len(Test_image), img_size, img_size, 3),dtype = np.float32)\n",
    "i=0\n",
    "for image in Test_image:\n",
    "    X_test[i]=img_to_array(image)\n",
    "    X_test[i]=Test_image[i]\n",
    "    i=i+1\n",
    "    \n",
    "X_test=X_test/255\n",
    "print('Test Shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with labels\n",
    "Y = Train.copy()\n",
    "del Y['image_id']\n",
    "Y.head()\n",
    "Y_train = np.array(Y.values)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the training set into training and testing set\n",
    "train_x,test_x,train_y,test_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1960, 100, 100, 3), array([490, 490, 490, 490]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with imbalanced dataset - oversampling\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state = 0) \n",
    " \n",
    "train_x,train_y = sm.fit_resample(train_x.reshape((-1, img_size * img_size * 3)), train_y)\n",
    "train_x = train_x.reshape((-1, img_size, img_size, 3))\n",
    "train_x.shape, train_y.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping and dynamic learning rates\n",
    "LR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                            factor=0.5,\n",
    "                            patience=10, # Change from 6\n",
    "                            min_lr=0.000001, # Change from 0.00001\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 96, 96, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 96, 96, 32)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 92, 92, 128)       102528    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 92, 92, 128)       384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 46, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 46, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 44, 44, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 44, 44, 128)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 42, 42, 128)       384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 17, 17, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 17, 17, 128)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 13, 13, 256)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               2509000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 4,154,628\n",
      "Trainable params: 4,152,500\n",
      "Non-trainable params: 2,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "reg = .0005\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5,5),activation='relu', input_shape=(img_size, img_size, 3), \n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.Conv2D(128, kernel_size=(5,5),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, kernel_size=(3,3),activation='relu', input_shape=(img_size, img_size, 3), \n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.Conv2D(128, kernel_size=(3,3),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, kernel_size=(5,5),activation='relu', input_shape=(img_size, img_size, 3), \n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.Conv2D(256, kernel_size=(5,5),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg)))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(200,activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(64,activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,center=True,scale=False))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(4,activation='softmax'))\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "# Just using flipping\n",
    "data_aug = ImageDataGenerator(horizontal_flip=True,\n",
    "                              vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 1.7917 - accuracy: 0.4013 - val_loss: 4.5025 - val_accuracy: 0.0438\n",
      "Epoch 2/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.5678 - accuracy: 0.4582 - val_loss: 3.4874 - val_accuracy: 0.0438\n",
      "Epoch 3/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 1.5434 - accuracy: 0.4556 - val_loss: 4.8080 - val_accuracy: 0.0438\n",
      "Epoch 4/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.4715 - accuracy: 0.4990 - val_loss: 2.2807 - val_accuracy: 0.1945\n",
      "Epoch 5/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.4302 - accuracy: 0.5052 - val_loss: 2.0025 - val_accuracy: 0.2630\n",
      "Epoch 6/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 1.3623 - accuracy: 0.5372 - val_loss: 2.1673 - val_accuracy: 0.2521\n",
      "Epoch 7/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.3382 - accuracy: 0.5434 - val_loss: 1.6348 - val_accuracy: 0.4137\n",
      "Epoch 8/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.2751 - accuracy: 0.5863 - val_loss: 1.4218 - val_accuracy: 0.4767\n",
      "Epoch 9/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 1.2407 - accuracy: 0.6055 - val_loss: 1.9005 - val_accuracy: 0.3288\n",
      "Epoch 10/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 1.1523 - accuracy: 0.6291 - val_loss: 1.5543 - val_accuracy: 0.4932\n",
      "Epoch 11/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 1.0672 - accuracy: 0.6842 - val_loss: 2.0813 - val_accuracy: 0.3479\n",
      "Epoch 12/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.9779 - accuracy: 0.7137 - val_loss: 2.0220 - val_accuracy: 0.3644\n",
      "Epoch 13/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.8771 - accuracy: 0.7655 - val_loss: 1.4582 - val_accuracy: 0.5342\n",
      "Epoch 14/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.8058 - accuracy: 0.7922 - val_loss: 1.3447 - val_accuracy: 0.6548\n",
      "Epoch 15/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.7836 - accuracy: 0.7993 - val_loss: 2.3637 - val_accuracy: 0.4247\n",
      "Epoch 16/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.6923 - accuracy: 0.8425 - val_loss: 2.0616 - val_accuracy: 0.5589\n",
      "Epoch 17/300\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.6609 - accuracy: 0.8471 - val_loss: 1.7318 - val_accuracy: 0.5562\n",
      "Epoch 18/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.6008 - accuracy: 0.8740 - val_loss: 1.0788 - val_accuracy: 0.7425\n",
      "Epoch 19/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5811 - accuracy: 0.8807 - val_loss: 1.1058 - val_accuracy: 0.7178\n",
      "Epoch 20/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5648 - accuracy: 0.8791 - val_loss: 0.8643 - val_accuracy: 0.7836\n",
      "Epoch 21/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.5901 - accuracy: 0.8683 - val_loss: 1.8463 - val_accuracy: 0.4164\n",
      "Epoch 22/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5549 - accuracy: 0.8791 - val_loss: 1.4422 - val_accuracy: 0.6137\n",
      "Epoch 23/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.4772 - accuracy: 0.9069 - val_loss: 1.8446 - val_accuracy: 0.5836\n",
      "Epoch 24/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5391 - accuracy: 0.8823 - val_loss: 0.8339 - val_accuracy: 0.8164\n",
      "Epoch 25/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.5092 - accuracy: 0.8936 - val_loss: 1.0581 - val_accuracy: 0.7507\n",
      "Epoch 26/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4915 - accuracy: 0.8967 - val_loss: 1.3969 - val_accuracy: 0.6959\n",
      "Epoch 27/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5157 - accuracy: 0.8853 - val_loss: 0.6658 - val_accuracy: 0.8493\n",
      "Epoch 28/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4477 - accuracy: 0.9194 - val_loss: 1.1570 - val_accuracy: 0.7479\n",
      "Epoch 29/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.4324 - accuracy: 0.9205 - val_loss: 0.7708 - val_accuracy: 0.8137\n",
      "Epoch 30/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4717 - accuracy: 0.9081 - val_loss: 0.8691 - val_accuracy: 0.7945\n",
      "Epoch 31/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4203 - accuracy: 0.9323 - val_loss: 1.0470 - val_accuracy: 0.7205\n",
      "Epoch 32/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.4348 - accuracy: 0.9213 - val_loss: 1.0658 - val_accuracy: 0.7616\n",
      "Epoch 33/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4037 - accuracy: 0.9292 - val_loss: 0.6806 - val_accuracy: 0.8356\n",
      "Epoch 34/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4018 - accuracy: 0.9298 - val_loss: 0.7104 - val_accuracy: 0.8219\n",
      "Epoch 35/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.3833 - accuracy: 0.9375 - val_loss: 0.6629 - val_accuracy: 0.8658\n",
      "Epoch 36/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.4253 - accuracy: 0.9206 - val_loss: 1.2776 - val_accuracy: 0.6767\n",
      "Epoch 37/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4372 - accuracy: 0.9280 - val_loss: 0.7288 - val_accuracy: 0.8603\n",
      "Epoch 38/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.4213 - accuracy: 0.9289 - val_loss: 1.0740 - val_accuracy: 0.7753\n",
      "Epoch 39/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4843 - accuracy: 0.9079 - val_loss: 1.7932 - val_accuracy: 0.5315\n",
      "Epoch 40/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.5083 - accuracy: 0.9075 - val_loss: 1.1343 - val_accuracy: 0.7479\n",
      "Epoch 41/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4262 - accuracy: 0.9372 - val_loss: 0.8216 - val_accuracy: 0.8055\n",
      "Epoch 42/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4388 - accuracy: 0.9306 - val_loss: 0.8501 - val_accuracy: 0.8603\n",
      "Epoch 43/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.4677 - accuracy: 0.9220 - val_loss: 0.8815 - val_accuracy: 0.8137\n",
      "Epoch 44/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.4312 - accuracy: 0.9375 - val_loss: 0.7666 - val_accuracy: 0.8521\n",
      "Epoch 45/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.3811 - accuracy: 0.9533 - val_loss: 0.9828 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 46/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.3673 - accuracy: 0.9551 - val_loss: 0.6514 - val_accuracy: 0.8685\n",
      "Epoch 47/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.3318 - accuracy: 0.9619 - val_loss: 0.6674 - val_accuracy: 0.8603\n",
      "Epoch 48/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.3194 - accuracy: 0.9664 - val_loss: 0.6458 - val_accuracy: 0.8740\n",
      "Epoch 49/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.2846 - accuracy: 0.9751 - val_loss: 0.5909 - val_accuracy: 0.8877\n",
      "Epoch 50/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.2849 - accuracy: 0.9717 - val_loss: 0.6221 - val_accuracy: 0.8822\n",
      "Epoch 51/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2660 - accuracy: 0.9726 - val_loss: 0.5682 - val_accuracy: 0.8877\n",
      "Epoch 52/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2673 - accuracy: 0.9706 - val_loss: 0.5780 - val_accuracy: 0.8904\n",
      "Epoch 53/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2501 - accuracy: 0.9756 - val_loss: 0.5602 - val_accuracy: 0.8849\n",
      "Epoch 54/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.2537 - accuracy: 0.9707 - val_loss: 0.7744 - val_accuracy: 0.8356\n",
      "Epoch 55/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.2487 - accuracy: 0.9768 - val_loss: 0.5894 - val_accuracy: 0.8795\n",
      "Epoch 56/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2813 - accuracy: 0.9632 - val_loss: 0.6401 - val_accuracy: 0.8740\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2785 - accuracy: 0.9671 - val_loss: 1.1112 - val_accuracy: 0.7370\n",
      "Epoch 58/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.2798 - accuracy: 0.9673 - val_loss: 0.8432 - val_accuracy: 0.8192\n",
      "Epoch 59/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2969 - accuracy: 0.9597 - val_loss: 1.9187 - val_accuracy: 0.6301\n",
      "Epoch 60/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2717 - accuracy: 0.9711 - val_loss: 0.9226 - val_accuracy: 0.8192\n",
      "Epoch 61/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2671 - accuracy: 0.9697 - val_loss: 0.6463 - val_accuracy: 0.8740\n",
      "Epoch 62/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.2741 - accuracy: 0.9704 - val_loss: 0.7692 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 63/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2455 - accuracy: 0.9793 - val_loss: 0.5638 - val_accuracy: 0.8932\n",
      "Epoch 64/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2458 - accuracy: 0.9742 - val_loss: 0.6038 - val_accuracy: 0.8904\n",
      "Epoch 65/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2151 - accuracy: 0.9861 - val_loss: 0.6112 - val_accuracy: 0.8795\n",
      "Epoch 66/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2190 - accuracy: 0.9830 - val_loss: 0.6204 - val_accuracy: 0.8658\n",
      "Epoch 67/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.2318 - accuracy: 0.9793 - val_loss: 0.5482 - val_accuracy: 0.8959\n",
      "Epoch 68/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.2091 - accuracy: 0.9830 - val_loss: 0.5801 - val_accuracy: 0.8986\n",
      "Epoch 69/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1905 - accuracy: 0.9902 - val_loss: 0.5564 - val_accuracy: 0.8959\n",
      "Epoch 70/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1874 - accuracy: 0.9866 - val_loss: 0.5911 - val_accuracy: 0.8932\n",
      "Epoch 71/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1892 - accuracy: 0.9897 - val_loss: 0.5923 - val_accuracy: 0.8877\n",
      "Epoch 72/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1960 - accuracy: 0.9855 - val_loss: 0.7743 - val_accuracy: 0.8466\n",
      "Epoch 73/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1824 - accuracy: 0.9876 - val_loss: 0.6419 - val_accuracy: 0.8932\n",
      "Epoch 74/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1734 - accuracy: 0.9876 - val_loss: 0.5563 - val_accuracy: 0.8959\n",
      "Epoch 75/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1833 - accuracy: 0.9813 - val_loss: 0.5686 - val_accuracy: 0.9014\n",
      "Epoch 76/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1739 - accuracy: 0.9871 - val_loss: 0.5758 - val_accuracy: 0.9041\n",
      "Epoch 77/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1903 - accuracy: 0.9809 - val_loss: 0.5474 - val_accuracy: 0.8986\n",
      "Epoch 78/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1723 - accuracy: 0.9876 - val_loss: 0.5783 - val_accuracy: 0.8849\n",
      "Epoch 79/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1779 - accuracy: 0.9855 - val_loss: 0.5220 - val_accuracy: 0.8877\n",
      "Epoch 80/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1814 - accuracy: 0.9840 - val_loss: 0.5149 - val_accuracy: 0.9068\n",
      "Epoch 81/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1805 - accuracy: 0.9845 - val_loss: 0.6624 - val_accuracy: 0.8493\n",
      "Epoch 82/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1821 - accuracy: 0.9804 - val_loss: 0.6831 - val_accuracy: 0.8740\n",
      "Epoch 83/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1666 - accuracy: 0.9861 - val_loss: 0.6532 - val_accuracy: 0.8712\n",
      "Epoch 84/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1592 - accuracy: 0.9892 - val_loss: 0.6146 - val_accuracy: 0.8877\n",
      "Epoch 85/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1504 - accuracy: 0.9923 - val_loss: 0.5880 - val_accuracy: 0.8986\n",
      "Epoch 86/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.1614 - accuracy: 0.9871 - val_loss: 0.5672 - val_accuracy: 0.8904\n",
      "Epoch 87/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1667 - accuracy: 0.9861 - val_loss: 0.6463 - val_accuracy: 0.8822\n",
      "Epoch 88/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1575 - accuracy: 0.9876 - val_loss: 0.6442 - val_accuracy: 0.8740\n",
      "Epoch 89/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1556 - accuracy: 0.9881 - val_loss: 0.7640 - val_accuracy: 0.8603\n",
      "Epoch 90/300\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.1534 - accuracy: 0.9912 - val_loss: 0.5482 - val_accuracy: 0.8959\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 91/300\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.1585 - accuracy: 0.9845 - val_loss: 0.5569 - val_accuracy: 0.9014\n",
      "Epoch 92/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1493 - accuracy: 0.9897 - val_loss: 0.5440 - val_accuracy: 0.8822\n",
      "Epoch 93/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.1464 - accuracy: 0.9907 - val_loss: 0.5389 - val_accuracy: 0.8959\n",
      "Epoch 94/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.1411 - accuracy: 0.9912 - val_loss: 0.4955 - val_accuracy: 0.8877\n",
      "Epoch 95/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.1295 - accuracy: 0.9948 - val_loss: 0.4707 - val_accuracy: 0.9178\n",
      "Epoch 96/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1288 - accuracy: 0.9933 - val_loss: 0.4719 - val_accuracy: 0.9123\n",
      "Epoch 97/300\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.1243 - accuracy: 0.9954 - val_loss: 0.4889 - val_accuracy: 0.9041\n",
      "Epoch 98/300\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.1205 - accuracy: 0.9974 - val_loss: 0.4763 - val_accuracy: 0.9068\n",
      "Epoch 99/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1290 - accuracy: 0.9933 - val_loss: 0.4696 - val_accuracy: 0.9205\n",
      "Epoch 100/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1185 - accuracy: 0.9959 - val_loss: 0.4954 - val_accuracy: 0.9205\n",
      "Epoch 101/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1248 - accuracy: 0.9922 - val_loss: 0.5309 - val_accuracy: 0.9041\n",
      "Epoch 102/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1264 - accuracy: 0.9923 - val_loss: 0.5211 - val_accuracy: 0.9178\n",
      "Epoch 103/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1187 - accuracy: 0.9954 - val_loss: 0.5152 - val_accuracy: 0.9068\n",
      "Epoch 104/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1168 - accuracy: 0.9954 - val_loss: 0.5463 - val_accuracy: 0.8986\n",
      "Epoch 105/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1162 - accuracy: 0.9948 - val_loss: 0.5139 - val_accuracy: 0.9123\n",
      "Epoch 106/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1218 - accuracy: 0.9917 - val_loss: 0.4986 - val_accuracy: 0.9096\n",
      "Epoch 107/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1120 - accuracy: 0.9943 - val_loss: 0.5038 - val_accuracy: 0.9178\n",
      "Epoch 108/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1092 - accuracy: 0.9943 - val_loss: 0.5256 - val_accuracy: 0.9151\n",
      "Epoch 109/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1063 - accuracy: 0.9959 - val_loss: 0.5134 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 110/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1092 - accuracy: 0.9969 - val_loss: 0.5147 - val_accuracy: 0.9151\n",
      "Epoch 111/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.1024 - accuracy: 0.9974 - val_loss: 0.4945 - val_accuracy: 0.9068\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 5s 62ms/step - loss: 0.1008 - accuracy: 0.9979 - val_loss: 0.4909 - val_accuracy: 0.9096\n",
      "Epoch 113/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.1009 - accuracy: 0.9964 - val_loss: 0.5038 - val_accuracy: 0.8986\n",
      "Epoch 114/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0972 - accuracy: 0.9969 - val_loss: 0.5037 - val_accuracy: 0.8959\n",
      "Epoch 115/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0981 - accuracy: 0.9959 - val_loss: 0.4930 - val_accuracy: 0.8959\n",
      "Epoch 116/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0923 - accuracy: 0.9979 - val_loss: 0.4896 - val_accuracy: 0.9151\n",
      "Epoch 117/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0931 - accuracy: 0.9985 - val_loss: 0.4924 - val_accuracy: 0.9096\n",
      "Epoch 118/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0935 - accuracy: 0.9979 - val_loss: 0.4915 - val_accuracy: 0.9151\n",
      "Epoch 119/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0891 - accuracy: 0.9979 - val_loss: 0.4860 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 120/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0890 - accuracy: 0.9990 - val_loss: 0.4787 - val_accuracy: 0.9096\n",
      "Epoch 121/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0916 - accuracy: 0.9964 - val_loss: 0.4803 - val_accuracy: 0.9041\n",
      "Epoch 122/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0890 - accuracy: 0.9969 - val_loss: 0.4844 - val_accuracy: 0.9068\n",
      "Epoch 123/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0871 - accuracy: 0.9979 - val_loss: 0.4869 - val_accuracy: 0.9068\n",
      "Epoch 124/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0873 - accuracy: 0.9979 - val_loss: 0.4815 - val_accuracy: 0.9068\n",
      "Epoch 125/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0877 - accuracy: 0.9974 - val_loss: 0.4929 - val_accuracy: 0.9123\n",
      "Epoch 126/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0872 - accuracy: 0.9979 - val_loss: 0.4825 - val_accuracy: 0.9123\n",
      "Epoch 127/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0876 - accuracy: 0.9969 - val_loss: 0.4745 - val_accuracy: 0.917877 - accura\n",
      "Epoch 128/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0849 - accuracy: 0.9990 - val_loss: 0.4637 - val_accuracy: 0.9178\n",
      "Epoch 129/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0864 - accuracy: 0.9974 - val_loss: 0.4657 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 130/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0815 - accuracy: 0.9990 - val_loss: 0.4760 - val_accuracy: 0.9123\n",
      "Epoch 131/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0827 - accuracy: 0.9979 - val_loss: 0.4716 - val_accuracy: 0.9123\n",
      "Epoch 132/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0811 - accuracy: 0.9985 - val_loss: 0.4707 - val_accuracy: 0.9123\n",
      "Epoch 133/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0860 - accuracy: 0.9969 - val_loss: 0.4683 - val_accuracy: 0.9123\n",
      "Epoch 134/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0815 - accuracy: 0.9985 - val_loss: 0.4656 - val_accuracy: 0.9151\n",
      "Epoch 135/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0819 - accuracy: 0.9985 - val_loss: 0.4717 - val_accuracy: 0.9068\n",
      "Epoch 136/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0816 - accuracy: 0.9990 - val_loss: 0.4733 - val_accuracy: 0.9123\n",
      "Epoch 137/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0822 - accuracy: 0.9969 - val_loss: 0.4760 - val_accuracy: 0.9068\n",
      "Epoch 138/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0853 - accuracy: 0.9974 - val_loss: 0.4773 - val_accuracy: 0.9096\n",
      "Epoch 139/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0778 - accuracy: 0.9995 - val_loss: 0.4767 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 140/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0835 - accuracy: 0.9964 - val_loss: 0.4838 - val_accuracy: 0.9151\n",
      "Epoch 141/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0787 - accuracy: 0.9990 - val_loss: 0.4824 - val_accuracy: 0.9123\n",
      "Epoch 142/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0807 - accuracy: 0.9985 - val_loss: 0.4817 - val_accuracy: 0.9068\n",
      "Epoch 143/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0774 - accuracy: 0.9995 - val_loss: 0.4818 - val_accuracy: 0.9068\n",
      "Epoch 144/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0790 - accuracy: 0.9990 - val_loss: 0.4790 - val_accuracy: 0.9068\n",
      "Epoch 145/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0788 - accuracy: 0.9984 - val_loss: 0.4789 - val_accuracy: 0.9123\n",
      "Epoch 146/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0781 - accuracy: 0.9985 - val_loss: 0.4780 - val_accuracy: 0.9096\n",
      "Epoch 147/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0772 - accuracy: 0.9995 - val_loss: 0.4799 - val_accuracy: 0.9096\n",
      "Epoch 148/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0776 - accuracy: 0.9990 - val_loss: 0.4785 - val_accuracy: 0.9096\n",
      "Epoch 149/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0782 - accuracy: 0.9990 - val_loss: 0.4724 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 150/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0782 - accuracy: 0.9990 - val_loss: 0.4741 - val_accuracy: 0.9096 0s - loss: 0.0781 - ac\n",
      "Epoch 151/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0800 - accuracy: 0.9974 - val_loss: 0.4752 - val_accuracy: 0.9096\n",
      "Epoch 152/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0811 - accuracy: 0.9979 - val_loss: 0.4743 - val_accuracy: 0.9096\n",
      "Epoch 153/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9096\n",
      "Epoch 154/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9096\n",
      "Epoch 155/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0803 - accuracy: 0.9985 - val_loss: 0.4728 - val_accuracy: 0.9096\n",
      "Epoch 156/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0759 - accuracy: 0.9995 - val_loss: 0.4729 - val_accuracy: 0.9096\n",
      "Epoch 157/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0820 - accuracy: 0.9964 - val_loss: 0.4719 - val_accuracy: 0.9096\n",
      "Epoch 158/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0761 - accuracy: 0.9995 - val_loss: 0.4746 - val_accuracy: 0.9096\n",
      "Epoch 159/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0797 - accuracy: 0.9964 - val_loss: 0.4729 - val_accuracy: 0.9123\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 160/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0783 - accuracy: 0.9974 - val_loss: 0.4728 - val_accuracy: 0.9096\n",
      "Epoch 161/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0754 - accuracy: 0.9995 - val_loss: 0.4712 - val_accuracy: 0.9096\n",
      "Epoch 162/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.0780 - accuracy: 0.9985 - val_loss: 0.4736 - val_accuracy: 0.9096\n",
      "Epoch 163/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0772 - accuracy: 0.9985 - val_loss: 0.4750 - val_accuracy: 0.9096\n",
      "Epoch 164/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0752 - accuracy: 0.9990 - val_loss: 0.4736 - val_accuracy: 0.9096\n",
      "Epoch 165/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0793 - accuracy: 0.9985 - val_loss: 0.4727 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0760 - accuracy: 0.9990 - val_loss: 0.4750 - val_accuracy: 0.9123\n",
      "Epoch 167/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0795 - accuracy: 0.9974 - val_loss: 0.4734 - val_accuracy: 0.9123\n",
      "Epoch 168/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0773 - accuracy: 0.9985 - val_loss: 0.4724 - val_accuracy: 0.9123\n",
      "Epoch 169/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0846 - accuracy: 0.9959 - val_loss: 0.4737 - val_accuracy: 0.9123\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 170/300\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.0768 - accuracy: 0.9990 - val_loss: 0.4719 - val_accuracy: 0.9123\n",
      "Epoch 171/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0803 - accuracy: 0.9969 - val_loss: 0.4746 - val_accuracy: 0.9123\n",
      "Epoch 172/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0758 - accuracy: 0.9995 - val_loss: 0.4742 - val_accuracy: 0.9123\n",
      "Epoch 173/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0761 - accuracy: 0.9995 - val_loss: 0.4745 - val_accuracy: 0.9123\n",
      "Epoch 174/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0805 - accuracy: 0.9964 - val_loss: 0.4713 - val_accuracy: 0.9123\n",
      "Epoch 175/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0744 - accuracy: 0.9990 - val_loss: 0.4727 - val_accuracy: 0.9096\n",
      "Epoch 176/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0777 - accuracy: 0.9974 - val_loss: 0.4718 - val_accuracy: 0.9123\n",
      "Epoch 177/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.0765 - accuracy: 0.9990 - val_loss: 0.4758 - val_accuracy: 0.9151\n",
      "Epoch 178/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0749 - accuracy: 0.9995 - val_loss: 0.4746 - val_accuracy: 0.9151\n",
      "Epoch 179/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0765 - accuracy: 0.9974 - val_loss: 0.4739 - val_accuracy: 0.9123\n",
      "Epoch 180/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0770 - accuracy: 0.9990 - val_loss: 0.4736 - val_accuracy: 0.9096\n",
      "Epoch 181/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0788 - accuracy: 0.9979 - val_loss: 0.4757 - val_accuracy: 0.9096\n",
      "Epoch 182/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0772 - accuracy: 0.9990 - val_loss: 0.4762 - val_accuracy: 0.9096\n",
      "Epoch 183/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0765 - accuracy: 0.9985 - val_loss: 0.4743 - val_accuracy: 0.9096\n",
      "Epoch 184/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0779 - accuracy: 0.9985 - val_loss: 0.4757 - val_accuracy: 0.9096\n",
      "Epoch 185/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0754 - accuracy: 0.9990 - val_loss: 0.4752 - val_accuracy: 0.9123\n",
      "Epoch 186/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0741 - accuracy: 0.9995 - val_loss: 0.4731 - val_accuracy: 0.9123\n",
      "Epoch 187/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0751 - accuracy: 0.9990 - val_loss: 0.4732 - val_accuracy: 0.9096\n",
      "Epoch 188/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0762 - accuracy: 0.9990 - val_loss: 0.4754 - val_accuracy: 0.9096\n",
      "Epoch 189/300\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.0782 - accuracy: 0.9984 - val_loss: 0.4726 - val_accuracy: 0.9123\n",
      "Epoch 190/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0795 - accuracy: 0.9969 - val_loss: 0.4726 - val_accuracy: 0.9123\n",
      "Epoch 191/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0767 - accuracy: 0.9979 - val_loss: 0.4749 - val_accuracy: 0.9123\n",
      "Epoch 192/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0748 - accuracy: 0.9995 - val_loss: 0.4722 - val_accuracy: 0.9123\n",
      "Epoch 193/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0773 - accuracy: 0.9990 - val_loss: 0.4710 - val_accuracy: 0.9151\n",
      "Epoch 194/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0753 - accuracy: 0.9995 - val_loss: 0.4701 - val_accuracy: 0.9123\n",
      "Epoch 195/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0759 - accuracy: 0.9995 - val_loss: 0.4723 - val_accuracy: 0.9096\n",
      "Epoch 196/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0787 - accuracy: 0.9974 - val_loss: 0.4743 - val_accuracy: 0.9123\n",
      "Epoch 197/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0744 - accuracy: 0.9995 - val_loss: 0.4742 - val_accuracy: 0.9123\n",
      "Epoch 198/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0739 - accuracy: 0.9995 - val_loss: 0.4721 - val_accuracy: 0.9151\n",
      "Epoch 199/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0771 - accuracy: 0.9985 - val_loss: 0.4742 - val_accuracy: 0.9123\n",
      "Epoch 200/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0773 - accuracy: 0.9979 - val_loss: 0.4709 - val_accuracy: 0.9123\n",
      "Epoch 201/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0757 - accuracy: 0.9984 - val_loss: 0.4762 - val_accuracy: 0.9151\n",
      "Epoch 202/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0756 - accuracy: 0.9979 - val_loss: 0.4734 - val_accuracy: 0.9123\n",
      "Epoch 203/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0741 - accuracy: 0.9995 - val_loss: 0.4705 - val_accuracy: 0.9123\n",
      "Epoch 204/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0753 - accuracy: 0.9985 - val_loss: 0.4758 - val_accuracy: 0.9123\n",
      "Epoch 205/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0757 - accuracy: 0.9985 - val_loss: 0.4723 - val_accuracy: 0.9123\n",
      "Epoch 206/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0780 - accuracy: 0.9974 - val_loss: 0.4737 - val_accuracy: 0.9123\n",
      "Epoch 207/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0760 - accuracy: 0.9985 - val_loss: 0.4736 - val_accuracy: 0.9123\n",
      "Epoch 208/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0776 - accuracy: 0.9974 - val_loss: 0.4730 - val_accuracy: 0.9123\n",
      "Epoch 209/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0741 - accuracy: 0.9990 - val_loss: 0.4715 - val_accuracy: 0.9151\n",
      "Epoch 210/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0751 - accuracy: 0.9995 - val_loss: 0.4727 - val_accuracy: 0.9151\n",
      "Epoch 211/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0751 - accuracy: 0.9985 - val_loss: 0.4705 - val_accuracy: 0.9123\n",
      "Epoch 212/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0755 - accuracy: 0.9995 - val_loss: 0.4734 - val_accuracy: 0.9123\n",
      "Epoch 213/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0789 - accuracy: 0.9979 - val_loss: 0.4721 - val_accuracy: 0.9123\n",
      "Epoch 214/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0767 - accuracy: 0.9979 - val_loss: 0.4724 - val_accuracy: 0.9151\n",
      "Epoch 215/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0741 - accuracy: 0.9995 - val_loss: 0.4724 - val_accuracy: 0.9151\n",
      "Epoch 216/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0781 - accuracy: 0.9969 - val_loss: 0.4708 - val_accuracy: 0.9123\n",
      "Epoch 217/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0775 - accuracy: 0.9969 - val_loss: 0.4693 - val_accuracy: 0.9123\n",
      "Epoch 218/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0743 - accuracy: 0.9990 - val_loss: 0.4729 - val_accuracy: 0.9123\n",
      "Epoch 219/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0734 - accuracy: 0.9995 - val_loss: 0.4735 - val_accuracy: 0.9123\n",
      "Epoch 220/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0766 - accuracy: 0.9985 - val_loss: 0.4753 - val_accuracy: 0.9151\n",
      "Epoch 221/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9096\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0742 - accuracy: 0.9990 - val_loss: 0.4728 - val_accuracy: 0.9123\n",
      "Epoch 223/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0760 - accuracy: 0.9990 - val_loss: 0.4727 - val_accuracy: 0.9151\n",
      "Epoch 224/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0739 - accuracy: 0.9995 - val_loss: 0.4761 - val_accuracy: 0.9123\n",
      "Epoch 225/300\n",
      "81/81 [==============================] - 5s 68ms/step - loss: 0.0739 - accuracy: 0.9995 - val_loss: 0.4711 - val_accuracy: 0.9123\n",
      "Epoch 226/300\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.0761 - accuracy: 0.9985 - val_loss: 0.4704 - val_accuracy: 0.9123\n",
      "Epoch 227/300\n",
      "81/81 [==============================] - 6s 69ms/step - loss: 0.0739 - accuracy: 0.9985 - val_loss: 0.4695 - val_accuracy: 0.9123\n",
      "Epoch 228/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0739 - accuracy: 0.9990 - val_loss: 0.4716 - val_accuracy: 0.9123\n",
      "Epoch 229/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0745 - accuracy: 0.9990 - val_loss: 0.4694 - val_accuracy: 0.9123\n",
      "Epoch 230/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0749 - accuracy: 0.9990 - val_loss: 0.4708 - val_accuracy: 0.9123\n",
      "Epoch 231/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0749 - accuracy: 0.9985 - val_loss: 0.4705 - val_accuracy: 0.9123\n",
      "Epoch 232/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0735 - accuracy: 0.9990 - val_loss: 0.4710 - val_accuracy: 0.9151\n",
      "Epoch 233/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0733 - accuracy: 0.9990 - val_loss: 0.4733 - val_accuracy: 0.9123\n",
      "Epoch 234/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0745 - accuracy: 0.9990 - val_loss: 0.4706 - val_accuracy: 0.9123\n",
      "Epoch 235/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0740 - accuracy: 0.9995 - val_loss: 0.4714 - val_accuracy: 0.9123\n",
      "Epoch 236/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0792 - accuracy: 0.9969 - val_loss: 0.4730 - val_accuracy: 0.9123\n",
      "Epoch 237/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0750 - accuracy: 0.9985 - val_loss: 0.4705 - val_accuracy: 0.9096\n",
      "Epoch 238/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0728 - accuracy: 0.9990 - val_loss: 0.4712 - val_accuracy: 0.9151\n",
      "Epoch 239/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0771 - accuracy: 0.9985 - val_loss: 0.4736 - val_accuracy: 0.9123\n",
      "Epoch 240/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0739 - accuracy: 0.9995 - val_loss: 0.4729 - val_accuracy: 0.9123\n",
      "Epoch 241/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0745 - accuracy: 0.9990 - val_loss: 0.4701 - val_accuracy: 0.9123\n",
      "Epoch 242/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0740 - accuracy: 0.9990 - val_loss: 0.4719 - val_accuracy: 0.9151\n",
      "Epoch 243/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0738 - accuracy: 0.9985 - val_loss: 0.4718 - val_accuracy: 0.9123\n",
      "Epoch 244/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0764 - accuracy: 0.9979 - val_loss: 0.4715 - val_accuracy: 0.9151\n",
      "Epoch 245/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0741 - accuracy: 0.9995 - val_loss: 0.4696 - val_accuracy: 0.9151\n",
      "Epoch 246/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0748 - accuracy: 0.9979 - val_loss: 0.4689 - val_accuracy: 0.9123\n",
      "Epoch 247/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9123\n",
      "Epoch 248/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0748 - accuracy: 0.9990 - val_loss: 0.4700 - val_accuracy: 0.9123\n",
      "Epoch 249/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0736 - accuracy: 0.9985 - val_loss: 0.4701 - val_accuracy: 0.9123\n",
      "Epoch 250/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0732 - accuracy: 0.9990 - val_loss: 0.4704 - val_accuracy: 0.9123\n",
      "Epoch 251/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0769 - accuracy: 0.9985 - val_loss: 0.4699 - val_accuracy: 0.9123\n",
      "Epoch 252/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0748 - accuracy: 0.9979 - val_loss: 0.4699 - val_accuracy: 0.9123\n",
      "Epoch 253/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0750 - accuracy: 0.9990 - val_loss: 0.4691 - val_accuracy: 0.9178\n",
      "Epoch 254/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0734 - accuracy: 0.9995 - val_loss: 0.4668 - val_accuracy: 0.9151\n",
      "Epoch 255/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9151\n",
      "Epoch 256/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0765 - accuracy: 0.9990 - val_loss: 0.4674 - val_accuracy: 0.9151\n",
      "Epoch 257/300\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.0745 - accuracy: 0.9984 - val_loss: 0.4689 - val_accuracy: 0.9178\n",
      "Epoch 258/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0746 - accuracy: 0.9979 - val_loss: 0.4680 - val_accuracy: 0.9178\n",
      "Epoch 259/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0750 - accuracy: 0.9985 - val_loss: 0.4689 - val_accuracy: 0.9178\n",
      "Epoch 260/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0761 - accuracy: 0.9974 - val_loss: 0.4691 - val_accuracy: 0.9123\n",
      "Epoch 261/300\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.0761 - accuracy: 0.9990 - val_loss: 0.4700 - val_accuracy: 0.9123\n",
      "Epoch 262/300\n",
      "81/81 [==============================] - 6s 68ms/step - loss: 0.0756 - accuracy: 0.9985 - val_loss: 0.4675 - val_accuracy: 0.9178\n",
      "Epoch 263/300\n",
      "81/81 [==============================] - 6s 68ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9178\n",
      "Epoch 264/300\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.0760 - accuracy: 0.9985 - val_loss: 0.4673 - val_accuracy: 0.9178\n",
      "Epoch 265/300\n",
      "81/81 [==============================] - 6s 69ms/step - loss: 0.0776 - accuracy: 0.9969 - val_loss: 0.4682 - val_accuracy: 0.9205\n",
      "Epoch 266/300\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.0760 - accuracy: 0.9979 - val_loss: 0.4693 - val_accuracy: 0.9123\n",
      "Epoch 267/300\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0753 - accuracy: 0.9985 - val_loss: 0.4686 - val_accuracy: 0.9205\n",
      "Epoch 268/300\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0737 - accuracy: 0.9990 - val_loss: 0.4683 - val_accuracy: 0.9205\n",
      "Epoch 269/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0731 - accuracy: 0.9979 - val_loss: 0.4696 - val_accuracy: 0.9205\n",
      "Epoch 270/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0727 - accuracy: 0.9995 - val_loss: 0.4692 - val_accuracy: 0.9178\n",
      "Epoch 271/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0758 - accuracy: 0.9979 - val_loss: 0.4667 - val_accuracy: 0.9178\n",
      "Epoch 272/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0776 - accuracy: 0.9979 - val_loss: 0.4695 - val_accuracy: 0.9151\n",
      "Epoch 273/300\n",
      "81/81 [==============================] - 5s 68ms/step - loss: 0.0730 - accuracy: 0.9990 - val_loss: 0.4681 - val_accuracy: 0.9178\n",
      "Epoch 274/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0724 - accuracy: 0.9990 - val_loss: 0.4677 - val_accuracy: 0.9178\n",
      "Epoch 275/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0740 - accuracy: 0.9979 - val_loss: 0.4697 - val_accuracy: 0.9178\n",
      "Epoch 276/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0726 - accuracy: 0.9995 - val_loss: 0.4681 - val_accuracy: 0.9151\n",
      "Epoch 277/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0752 - accuracy: 0.9969 - val_loss: 0.4684 - val_accuracy: 0.9178\n",
      "Epoch 278/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0727 - accuracy: 0.9985 - val_loss: 0.4703 - val_accuracy: 0.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0743 - accuracy: 0.9990 - val_loss: 0.4679 - val_accuracy: 0.9178\n",
      "Epoch 280/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0721 - accuracy: 0.9990 - val_loss: 0.4703 - val_accuracy: 0.9151\n",
      "Epoch 281/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0731 - accuracy: 0.9990 - val_loss: 0.4710 - val_accuracy: 0.9151\n",
      "Epoch 282/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0764 - accuracy: 0.9969 - val_loss: 0.4685 - val_accuracy: 0.9178\n",
      "Epoch 283/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0723 - accuracy: 0.9995 - val_loss: 0.4725 - val_accuracy: 0.9151\n",
      "Epoch 284/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0732 - accuracy: 0.9985 - val_loss: 0.4709 - val_accuracy: 0.9151\n",
      "Epoch 285/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0777 - accuracy: 0.9969 - val_loss: 0.4701 - val_accuracy: 0.9151\n",
      "Epoch 286/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0725 - accuracy: 0.9990 - val_loss: 0.4671 - val_accuracy: 0.9151\n",
      "Epoch 287/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0740 - accuracy: 0.9990 - val_loss: 0.4706 - val_accuracy: 0.9151\n",
      "Epoch 288/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0731 - accuracy: 0.9985 - val_loss: 0.4698 - val_accuracy: 0.9178\n",
      "Epoch 289/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0723 - accuracy: 0.9995 - val_loss: 0.4700 - val_accuracy: 0.9123\n",
      "Epoch 290/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0749 - accuracy: 0.9979 - val_loss: 0.4694 - val_accuracy: 0.9151\n",
      "Epoch 291/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0730 - accuracy: 0.9979 - val_loss: 0.4750 - val_accuracy: 0.9096\n",
      "Epoch 292/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0747 - accuracy: 0.9984 - val_loss: 0.4684 - val_accuracy: 0.9151\n",
      "Epoch 293/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0738 - accuracy: 0.9990 - val_loss: 0.4690 - val_accuracy: 0.9151\n",
      "Epoch 294/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0739 - accuracy: 0.9974 - val_loss: 0.4718 - val_accuracy: 0.9123\n",
      "Epoch 295/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0745 - accuracy: 0.9995 - val_loss: 0.4700 - val_accuracy: 0.9123\n",
      "Epoch 296/300\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0742 - accuracy: 0.9990 - val_loss: 0.4655 - val_accuracy: 0.9178\n",
      "Epoch 297/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0732 - accuracy: 0.9990 - val_loss: 0.4714 - val_accuracy: 0.9123\n",
      "Epoch 298/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0735 - accuracy: 0.9979 - val_loss: 0.4674 - val_accuracy: 0.9151\n",
      "Epoch 299/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0757 - accuracy: 0.9979 - val_loss: 0.4706 - val_accuracy: 0.9151\n",
      "Epoch 300/300\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0725 - accuracy: 0.9990 - val_loss: 0.4703 - val_accuracy: 0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d17c435448>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start to train model\n",
    "model.fit_generator(data_aug.flow(train_x,train_y,batch_size=24), # Change from 32\n",
    "                    steps_per_epoch=train_x.shape[0]//24,\n",
    "                    epochs=300, # Change from 200\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_x,test_y),\n",
    "                    callbacks=[LR_reduce],\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d157430dc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "history = model.history.history\n",
    "offset = 1\n",
    "epochs = range(offset, len(history['loss']))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(epochs, history['loss'][offset:], label='train')\n",
    "plt.plot(epochs, history['val_loss'][offset:], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d1574e0b48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(history[f'accuracy'], label='train')\n",
    "plt.plot(history[f'val_accuracy'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = Test.copy()\n",
    "del Y1['image_id']\n",
    "Y1.head()\n",
    "Y_test = np.array(Y1.values)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the testing set\n",
    "predict_prob = model.predict(X_test)\n",
    "df_predict_prob = pd.DataFrame(predict_prob, columns=['healthy','multiple_diseases','rust','scab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv files for submission\n",
    "frame = [Test['image_id'], df_predict_prob]\n",
    "df_submission = pd.concat(frame, axis=1)\n",
    "df_submission.to_csv(r'submisson.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
