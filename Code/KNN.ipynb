{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# progress bar for pandas\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read labels & Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "SAMPLE_LEN = 1821\n",
    "IMAGE_PATH = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63121530baaf4a47bec11353e3be26f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1821), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_id):\n",
    "    file_path = image_id + \".jpg\"\n",
    "    image = cv2.imread(IMAGE_PATH + file_path)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "train_images = train_data[\"image_id\"][:SAMPLE_LEN].progress_apply(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4eec98ea77438d8a862d79776d89fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1821), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = test_data[\"image_id\"][:SAMPLE_LEN].progress_apply(load_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert labels to label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = train_data[['healthy', 'multiple_diseases', 'rust', 'scab']]\n",
    "# rust = 3, scab = 4, healthy = 1, multiple_diseases = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "labels = [[1],[2],[3],[4]]\n",
    "encoder = enc.fit(labels)\n",
    "decoded_labels = encoder.inverse_transform(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 516.]\n",
      " [  2.  91.]\n",
      " [  3. 622.]\n",
      " [  4. 592.]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(decoded_labels, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize hog with default parameters\n",
    "winSize = (16,16)\n",
    "blockSize = (16,16)\n",
    "blockStride = (8,8)\n",
    "cellSize = (8,8)\n",
    "nbins = 9\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "winStride = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "hog_tr = [hog.compute(cv2.resize(im,(136,136),interpolation=cv2.INTER_AREA),winStride).reshape(9216) for im in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_tr2 = [hog.compute(cv2.resize(im,(200,200),interpolation=cv2.INTER_AREA),winStride).reshape(20736) for im in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "hog_te = [hog.compute(cv2.resize(im,(136,136),interpolation=cv2.INTER_AREA),winStride).reshape(9216) for im in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_te2 = [hog.compute(cv2.resize(im,(200,200),interpolation=cv2.INTER_AREA),winStride).reshape(20736) for im in test_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing (interpolation method, inter area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner area\n",
    "img_size = 100\n",
    "ptrain_images = []\n",
    "for image in train_images:\n",
    "    image=cv2.resize(image,(img_size,img_size),interpolation=cv2.INTER_AREA)\n",
    "    ptrain_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner area\n",
    "ptest_images = []\n",
    "for image in test_images:\n",
    "    image=cv2.resize(image,(img_size,img_size),interpolation=cv2.INTER_AREA)\n",
    "    ptest_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and vectorizing blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_train = [(ptrain_images[idx][:,:,2].reshape(img_size**2)) for idx in range(len(ptrain_images))]\n",
    "blue_train = np.array(blue_train)\n",
    "blue_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_test = [(ptest_images[idx][:,:,2].reshape(img_size**2)) for idx in range(len(ptest_images))]\n",
    "blue_test = np.array(blue_test)\n",
    "blue_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 30000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.ndarray(shape=(len(ptrain_images), img_size*img_size*3), dtype=np.float32)\n",
    "for i, image in enumerate(ptrain_images):\n",
    "    X_train[i,] = image.reshape(img_size*img_size*3)\n",
    "X_train.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 30000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.ndarray(shape=(len(ptest_images), img_size*img_size*3), dtype=np.float32)\n",
    "for i, image in enumerate(ptest_images):\n",
    "    X_test[i,] = image.reshape(img_size*img_size*3)\n",
    "X_test.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2488, 30000), (2488,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training data with all 3 channels\n",
    "y_train = decoded_labels.ravel()\n",
    "sm = SMOTE(random_state = 0) \n",
    "X_train, y_train = sm.fit_resample(X_train,y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2488, 10000), (2488,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training data with only the blue channel \n",
    "y_tr_blue = decoded_labels.ravel()\n",
    "sm_blue = SMOTE(random_state = 0) \n",
    "blue_train, y_tr_blue = sm_blue.fit_resample(blue_train, y_tr_blue)\n",
    "blue_train.shape, y_tr_blue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2488, 9216), (2488,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training data preprocess with HOG (smaller dimension)\n",
    "y_tr_hog = decoded_labels.ravel()\n",
    "sm_hog = SMOTE(random_state = 0) \n",
    "hog_tr, y_tr_hog = sm_hog.fit_resample(hog_tr, y_tr_hog)\n",
    "hog_tr.shape, y_tr_hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2488, 20736), (2488,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training data preprocess with HOG (larger dimension)\n",
    "y_tr_hog2 = decoded_labels.ravel()\n",
    "hog_tr2, y_tr_hog2 = sm_hog.fit_resample(hog_tr2, y_tr_hog2)\n",
    "hog_tr2.shape, y_tr_hog2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 622.]\n",
      " [  2. 622.]\n",
      " [  3. 622.]\n",
      " [  4. 622.]]\n"
     ]
    }
   ],
   "source": [
    "# inspect composition of labels after oversampling\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (blue channel only)  Kaggle Score = 0.50302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [3, 5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV with Grid Search\n",
    "parameters = {\n",
    "    'n_neighbors' : [3, 5, 10, 20],\n",
    "}\n",
    "Grid_KNNb = GridSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=5)\n",
    "Grid_KNNb.fit(blue_train, y_tr_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.43086816720257237\n",
      "Best parameters set:\n",
      "n_neighbors:3\n"
     ]
    }
   ],
   "source": [
    "# display accuracy and best hyperparameters\n",
    "print_grid_search_metrics(Grid_KNNb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict \n",
    "Knnb_pred = Grid_KNNb.predict(blue_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1 1192]\n",
      " [   2   99]\n",
      " [   3  162]\n",
      " [   4  368]]\n"
     ]
    }
   ],
   "source": [
    "# inspect composition of labels\n",
    "unique, counts = np.unique(Knnb_pred, return_counts=True)\n",
    "print (np.asarray([unique, counts], dtype=np.int32).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv files for submission\n",
    "labels = pd.get_dummies(Knnb_pred)\n",
    "labels.columns=['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "knnb_result = test_data.join(labels)\n",
    "knnb_result.to_csv(\"knnb_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.columns=['healthy', 'multiple_diseases', 'rust', 'scab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (all channels) Kaggle score = 0.51046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [3, 5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV with Grid Search\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "parameters = {\n",
    "    'n_neighbors' : [3, 5, 10, 20],\n",
    "}\n",
    "Grid_KNN = GridSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=5)\n",
    "Grid_KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.40836012861736337\n",
      "Best parameters set:\n",
      "n_neighbors:3\n"
     ]
    }
   ],
   "source": [
    "# display accuracy and best hyperparameters\n",
    "print_grid_search_metrics(Grid_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "Knn_pred = Grid_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  601]\n",
      " [   2 1040]\n",
      " [   3   23]\n",
      " [   4  157]]\n"
     ]
    }
   ],
   "source": [
    "# inspect composition of labels\n",
    "unique, counts = np.unique(Knn_pred, return_counts=True)\n",
    "print (np.asarray([unique, counts], dtype=np.int32).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output csv files for submission\n",
    "labels = pd.get_dummies(Knn_pred)\n",
    "labels.columns=['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "Knn_result = test_data.join(labels)\n",
    "Knn_result.to_csv(\"Knn_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with HOG (vec_len 9216)  Kaggle score = 0.54315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [3, 5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV with Grid Search\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "parameters = {\n",
    "    'n_neighbors' : [3, 5, 10, 20],\n",
    "}\n",
    "Grid_Khog = GridSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=5)\n",
    "Grid_Khog.fit(hog_tr, y_tr_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3842443729903537\n",
      "Best parameters set:\n",
      "n_neighbors:3\n"
     ]
    }
   ],
   "source": [
    "# display accuracy and best hyperparameters\n",
    "print_grid_search_metrics(Grid_Khog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and output csv files for submission\n",
    "Khog_pred = Grid_Khog.predict(hog_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  471]\n",
      " [   2 1239]\n",
      " [   4  111]]\n"
     ]
    }
   ],
   "source": [
    "# inspect composition of labels\n",
    "unique, counts = np.unique(Khog_pred, return_counts=True)\n",
    "print (np.asarray([unique, counts], dtype=np.int32).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv files for submission\n",
    "labels = pd.get_dummies(np.append(Khog_pred, 3))\n",
    "labels.columns=['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "Khog_result = test_data.join(labels[:-1])\n",
    "Khog_result.to_csv(\"Khog_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with HOG (vec_len 20736)  Kaggle score = 0.52084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [3, 5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV with Grid Search\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "parameters = {\n",
    "    'n_neighbors' : [3, 5, 10, 20],\n",
    "}\n",
    "Grid_Khog2 = GridSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=5)\n",
    "Grid_Khog2.fit(hog_tr2, y_tr_hog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.39308681672025725\n",
      "Best parameters set:\n",
      "n_neighbors:3\n"
     ]
    }
   ],
   "source": [
    "# display accuracy and best hyperparameters\n",
    "print_grid_search_metrics(Grid_Khog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and output csv files for submission\n",
    "Khog_pred2 = Grid_Khog2.predict(hog_te2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  535]\n",
      " [   2 1221]\n",
      " [   4   65]]\n"
     ]
    }
   ],
   "source": [
    "# inspect composition of labels\n",
    "unique, counts = np.unique(Khog_pred2, return_counts=True)\n",
    "print (np.asarray([unique, counts], dtype=np.int32).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv files for submission\n",
    "labels = pd.get_dummies(np.append(Khog_pred2, 3))\n",
    "labels.columns=['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "Khog_result2 = test_data.join(labels[:-1])\n",
    "Khog_result2.to_csv(\"Khog_result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
